---
title: "Models for set 3, F2 results (GAMM modelling strategies)"
author: "Márton Sóskuthy"
date: "25/05/2018"
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This document is a supplement to "Evaluating generalised additive mixed modelling strategies for dynamic speech analysis," relating specifically to the contents of Table 5 in Section 3.3. It presents code that illustrates (i) how the simulated data were generated and (ii) the models whose performance is summarised Table 5.

## Preliminaries

The code below loads the relevant libraries.

```{r, message=F}
library(ggplot2)
library(mgcv)
library(itsadug)
library(MASS)
```

## Data generation

The code in this section can be used to create data for either type I or type II simulations. Set the value of *type* to 1 for type I simulations and to 2 for type II simulations.

```{r}
type = 1
```

The data for this set of simulations consist of simulated f2 trajectories loosely modelled after the diphthong /eI/. In this simulation, there are 50 different word types, each of which is represented by 10 trajectories. Five of these trajectories are assigned to group A and five to group B - in other words, these simulations exemplify a within-item design. For type I simulations, there is no underlying difference between the two groups. For type II simulations, the underlying trajectories are slightly different (cf. Section 2.1 in the paper and also the Appendix).

The following code sets the parameters that determine the main characteristics of the data set.

```{r}
# setting time dimension (these are the points along which the trajectories are generated)
xs_dense = seq(0,1,0.05)

# indices for extracting every second measurement; this is used for downsampling
xs_thin_ind = c(rep(c(T,F), (length(xs_dense)-1)/2), T)

# population parameters: individual words come from this dist
f2_start_mean = 1500
f2_end_1_mean = 2000
if (type==2) {
  f2_end_2_mean = 1960
} else {
  f2_end_2_mean = 2000
}
f2_start_sd.word = 40 # population level sd
f2_end_sd.word = 40 # population level sd
# correlation between pairs of parameter values sampled for two groups within same word;
# (this is necessary, since now there are two distinct groups per word; these correlation
# parameters ensure that there is some consistency at the word level as well as within
# the groups)
# rho = 7/8 means that the sd of the difference between the two groups within
#   the same word is 0.5 * the sd of the target values
# in mixed model lingo: the sd of the random slope is half of the sd of the intercept
f2_start_rho.word = 7/8 # population level rho
f2_end_rho.word = 7/8 # population level rho

# expected value & sd for transition point
x0_mean = 0.35
x0_sd.word = 0.020 # population level sd
x0_rho.word = 7/8 #  population level rho (same as above)
# expected value & sd for steepness (higher -> more steep)
k_mean = 25
k_sd.word = 4 # population level sd
k_rho.word = 7/8 #  population level rho (same as above)

# how much variation within word-group pairs? (unchanged from before)
f2_start_sd.traj = 30 # trajectory level sd
f2_end_sd.traj = 30 # trajectory level sd
x0_sd.traj = 0.015 # trajectory level sd
k_sd.traj = 3 # trajectory level sd

# amount of random noise

noise_sd <- 5

n_words <- 50
n_trajectories_per_word <- 10
```

The code below assembles the dense version of the data set.

```{r}
# convenience function fid creating covariance matrix from sd's and correlation parameter
make_cov_matrix <- function (a.sd, b.sd, rho) {
  matrix(c(a.sd**2, rho*a.sd*b.sd, rho*a.sd*b.sd, b.sd**2), nrow=2)
}

# creating matrix that will store the trajectories
ys_m <- matrix(0, nrow=length(xs_dense), ncol=n_words*n_trajectories_per_word)
for (i in 1:n_words) {
  # sampling targets for groups A and B for a given word
  f2_start.word <- mvrnorm(1, rep(f2_start_mean, 2), 
                           make_cov_matrix(f2_start_sd.word, f2_start_sd.word, f2_start_rho.word))
  f2_end.word <- mvrnorm(1, c(f2_end_1_mean, f2_end_2_mean), 
                         make_cov_matrix(f2_end_sd.word, f2_end_sd.word, f2_end_rho.word))
  x0.word <- mvrnorm(1, rep(x0_mean, 2), 
                     make_cov_matrix(x0_sd.word, x0_sd.word, x0_rho.word))
  k.word <- mvrnorm(1, rep(k_mean, 2), 
                     make_cov_matrix(k_sd.word, k_sd.word, k_rho.word))
  for (j in 1:(n_trajectories_per_word/2)) {
    # sampling trajectories for group A
    f2_start <- rnorm(1, f2_start.word[1], f2_start_sd.traj)
    f2_end <- rnorm(1, f2_end.word[1], f2_end_sd.traj)
    x0 <- rnorm(1, x0.word[1], x0_sd.traj)
    k <- rnorm(1, k.word[1], k_sd.traj)
    ys_m[,(i-1)*n_trajectories_per_word + j*2 - 1] <- ((f2_end - f2_start) / (1 + exp(-k*(xs_dense-x0)))) + f2_start + rnorm(length(xs_dense), 0, noise_sd)
    # sampling trajectories for group B
    f2_start <- rnorm(1, f2_start.word[2], f2_start_sd.traj)
    f2_end <- rnorm(1, f2_end.word[2], f2_end_sd.traj)
    x0 <- rnorm(1, x0.word[2], x0_sd.traj)
    k <- rnorm(1, k.word[2], k_sd.traj)
    ys_m[,(i-1)*n_trajectories_per_word + j*2] <- ((f2_end - f2_start) / (1 + exp(-k*(xs_dense-x0)))) + f2_start + rnorm(length(xs_dense), 0, noise_sd)
  }
}

# assembling data set (randomly assigned to categories)
dat_dense <- data.frame(traj=paste("traj_", rep(1:(n_words*n_trajectories_per_word), each=length(xs_dense)), sep=""),
                  word=paste("word_", rep(1:n_words, each=length(xs_dense)*n_trajectories_per_word), sep=""),
                  group=rep(c("A","B"), each=length(xs_dense), times=n_words*n_trajectories_per_word / 2),
                  measurement.no=xs_dense, 
                  f2=c(ys_m),
                  stringsAsFactors = F
                 )

# setting up different types of grouping factors
dat_dense$group.factor <- as.factor(dat_dense$group)
dat_dense$group.ordered <- as.ordered(dat_dense$group)
contrasts(dat_dense$group.ordered) <- "contr.treatment"
dat_dense$group.bin <- as.numeric(dat_dense$group.factor) - 1

# traj/word ids must be factors  
dat_dense$traj <- as.factor(dat_dense$traj)
dat_dense$word <- as.factor(dat_dense$word)
dat_dense$wordGroup <- interaction(dat_dense$word, dat_dense$group)

# add dat$start for AR.start (for autoregressive error models)

dat_dense$start <- dat_dense$measurement.no == 0
```

Downsampling to thin version of the data set.

```{r}
dat_thin <- dat_dense[rep(xs_thin_ind, n_words*n_trajectories_per_word),]
```

Here is what the data set looks like.

```{r}
ggplot(dat_dense, aes(x=measurement.no, y=f2, group=traj, col=group)) +
  geom_line() +
  facet_wrap(~word)
```

## Models

All the models (and sets of models) from Table 5 are shown below in the same order as in the table. Note that all models contain AR1 components to deal with dependencies within trajectories. For simplicity, the rho value used for these AR1 components is taken from a single model fitted without any random structures. This model is estimated below.

```{r}
# dense
rho_mod_dense <- bam(f2 ~ group.ordered + 
                      s(measurement.no, bs = "tp", k = 10) + 
                      s(measurement.no, by = group.ordered, bs = "tp", k = 10), 
                    data = dat_dense, method = "fREML", discrete = T, nthreads = 1)

# thin
rho_mod_thin <- bam(f2 ~ group.ordered + 
                     s(measurement.no, bs = "tp", k = 10) + 
                     s(measurement.no, by = group.ordered, bs = "tp", k = 10), 
                   data = dat_thin, method = "fREML", discrete = T, nthreads = 1)

rho_dense <- start_value_rho(rho_mod_dense)
rho_thin <- start_value_rho(rho_mod_thin)
```

### 1. Random smooth by word, 3 bs

```{r}
# dense
rand_smooth_3_dense <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 3), 
      data = dat_dense, 
      AR.start = dat_dense$start, rho = rho_dense, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_smooth_3_dense)

# thin
rand_smooth_3_thin <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 3), 
      data = dat_thin, 
      AR.start = dat_thin$start, rho = rho_thin, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_smooth_3_thin)
```

### 2. Random smooth by word, 5 bs

```{r}
# dense
rand_smooth_5_dense <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 5), 
      data = dat_dense, 
      AR.start = dat_dense$start, rho = rho_dense, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_smooth_5_dense)

# thin
rand_smooth_5_thin <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 5), 
      data = dat_thin, 
      AR.start = dat_thin$start, rho = rho_thin, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_smooth_5_thin)
```

### 3. Random smooth by word, 10 bs

```{r}
# dense
rand_smooth_10_dense <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 10), 
      data = dat_dense, 
      AR.start = dat_dense$start, rho = rho_dense, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_smooth_10_dense)

# thin
rand_smooth_10_thin <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 10), 
      data = dat_thin, 
      AR.start = dat_thin$start, rho = rho_thin, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_smooth_10_thin)
```

### 4. Random smooth by word, 3 bs + random slope over group by word

```{r}
# dense
rand_slope_smooth_3_dense <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 3) +
        s(word, group.ordered, bs="re"), 
      data = dat_dense, 
      AR.start = dat_dense$start, rho = rho_dense, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_slope_smooth_3_dense)

# thin
rand_slope_smooth_3_thin <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 3) +
        s(word, group.ordered, bs="re"), 
      data = dat_thin, 
      AR.start = dat_thin$start, rho = rho_thin, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_slope_smooth_3_thin)
```

### 5. Random smooth by word, 5 bs + random slope over group by word

```{r}
# dense
rand_slope_smooth_5_dense <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 5) +
        s(word, group.ordered, bs="re"), 
      data = dat_dense, 
      AR.start = dat_dense$start, rho = rho_dense, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_slope_smooth_5_dense)

# thin
rand_slope_smooth_5_thin <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 5) +
        s(word, group.ordered, bs="re"), 
      data = dat_thin, 
      AR.start = dat_thin$start, rho = rho_thin, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_slope_smooth_5_thin)
```

### 6. Random smooth by word, 3 bs + random slope over group by word

```{r}
# dense
rand_slope_smooth_10_dense <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 10) +
        s(word, group.ordered, bs="re"), 
      data = dat_dense, 
      AR.start = dat_dense$start, rho = rho_dense, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_slope_smooth_10_dense)

# thin
rand_slope_smooth_10_thin <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, word, bs = "fs", m = 1, xt = "tp", k = 10) +
        s(word, group.ordered, bs="re"), 
      data = dat_thin, 
      AR.start = dat_thin$start, rho = rho_thin, 
      method = "fREML", discrete = T, nthreads = 1)
summary(rand_slope_smooth_10_thin)
```

### 7. Item x effect random smooths, 3 bs

```{r}
# dense
item_effect_rand_smooth_3_dense <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, wordGroup, bs = "fs", m = 1, xt = "tp", k = 3), 
      data = dat_dense, 
      AR.start = dat_dense$start, rho = rho_dense, 
      method = "fREML", discrete = T, nthreads = 1)
summary(item_effect_rand_smooth_3_dense)

# thin
item_effect_rand_smooth_3_thin <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, wordGroup, bs = "fs", m = 1, xt = "tp", k = 3), 
      data = dat_thin, 
      AR.start = dat_thin$start, rho = rho_thin, 
      method = "fREML", discrete = T, nthreads = 1)
summary(item_effect_rand_smooth_3_thin)
```

### 8. Item x effect random smooths, 5 bs

```{r}
# dense
item_effect_rand_smooth_5_dense <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, wordGroup, bs = "fs", m = 1, xt = "tp", k = 5), 
      data = dat_dense, 
      AR.start = dat_dense$start, rho = rho_dense, 
      method = "fREML", discrete = T, nthreads = 1)
summary(item_effect_rand_smooth_5_dense)

# thin
item_effect_rand_smooth_5_thin <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, wordGroup, bs = "fs", m = 1, xt = "tp", k = 5), 
      data = dat_thin, 
      AR.start = dat_thin$start, rho = rho_thin, 
      method = "fREML", discrete = T, nthreads = 1)
summary(item_effect_rand_smooth_5_thin)
```

### 9. Item x effect random smooths, 10 bs

```{r}
# dense
item_effect_rand_smooth_10_dense <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, wordGroup, bs = "fs", m = 1, xt = "tp", k = 10), 
      data = dat_dense, 
      AR.start = dat_dense$start, rho = rho_dense, 
      method = "fREML", discrete = T, nthreads = 1)
summary(item_effect_rand_smooth_10_dense)

# thin
item_effect_rand_smooth_10_thin <- 
  bam(f2 ~ group.ordered + 
        s(measurement.no, bs = "tp", k = 10) + 
        s(measurement.no, by = group.ordered, bs = "tp", k = 10) + 
        s(measurement.no, wordGroup, bs = "fs", m = 1, xt = "tp", k = 10), 
      data = dat_thin, 
      AR.start = dat_thin$start, rho = rho_thin, 
      method = "fREML", discrete = T, nthreads = 1)
summary(item_effect_rand_smooth_10_thin)
```

